1. 4채널이 왜 16채널이 됐는지, 왜 16채널을 쓰는지
SD VAE : convolusional autoencoder, 4 chennels, 
FLUX VAE : convolusional autoencoder, 16 chennels, 학습에 투입되는 계산량 SD VAE보다 늘려서 Reconstruction capability가 뛰어남, 구체적인 파라미터 수 공개 X

2. 리니어, 모듈레이션, 임베딩 블록 구체적으로 어떻게 되는지(단순히 리니어 프로젝션을 말하는지 아니면 파라미터가 존재하는지)
=> 파라미터 존재
Linear Layer
- 단순한 차원 축소나 확장이 아니라, **학습 가능한 가중치 행렬(W)과 편향(b)을 가진 완전 연결 층(Fully Connected Layer)**입니다.
- 입력 데이터(이미지 잠재 벡터 16채널, T5 텍스트 4,096채널 등)를 모델의 내부 숨겨진 차원(d)으로 매핑
Modulation Block
- vec 코디네이션 정보를 처리하여 어텐션 블록을 제어하는 파라미터 추출 네트워크
- 중간에 있는 Linear 레이어가 핵심 파라미터를 보유함, 입력된 컨텍스트 벡터로부터 각 층에 필요한 shift(이동), scale(크기 조절), gate(게이트) 값을 계산해냄
Embedding & MLP Blocks
- 타임스텝은 먼저 사인파(Sinusoidal) 방식으로 인코딩된 후 MLP Emb. 블록을 통과합니다
- **Linear -> SiLU -> Linear**의 2층 구조로 되어 있어, 단순한 숫자값이 아닌 고차원적인 특징을 추출할 수 있는 파라미터들이 존재

3. 더블스트림 블록이 19개라고 했는데 하나의 더블 스트림 블록에 파라미터가 들어가는데 파라미터 안에 1000만개가 있으면 그게 19개가 있으면 1억 9천만개인지 아니면 하나 학습된게 동일하게 있는건지
- 19개 블록이 각각 서로 다른 가중치(Weight)를 학습

4.  shape 다 써주기


+멀티뷰도 FLUX로 만들면 더 좋아지는 거 아닌가 생각해보기
